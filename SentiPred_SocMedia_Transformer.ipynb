{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentiPred_SocMedia_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juglar-diaz/SentimentAnalysis/blob/master/SentiPred_SocMedia_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02j_-p6TZ2r",
        "colab_type": "text"
      },
      "source": [
        "#Intro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3QjBnH6lktK",
        "colab_type": "code",
        "outputId": "93ad81f5-243c-4d3a-e159-e57c587ee68b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leX0hKWxlPaF",
        "colab_type": "code",
        "outputId": "e5e5beca-4fb5-41bd-ae1c-a0a64a1d01fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install stop_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32916 sha256=65a3b0f92e898a22d9d3ef46850f8a8bcb861568918110c0a986b5e70fa4b44a\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsKFofSByI9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -q tensorflow-text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosahS5t0nH3",
        "colab_type": "code",
        "outputId": "16fae23a-7757-487f-9bcb-1399533f791d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "#!pip install -q tf-nightly-gpu-2.0-preview\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 69kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 42.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhfa7bn4ypPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeqX7HRpBigk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "from collections import Counter\n",
        "from stop_words import get_stop_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9kkYk9lXhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4n58fkig5KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import itertools\n",
        "\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "sep = os.sep\n",
        "import os.path\n",
        "\n",
        "import pandas as pd\n",
        "import bisect\n",
        "import time\n",
        "import scipy.stats as stats\n",
        "\n",
        "import datetime\n",
        "\n",
        "import glob\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jjmwC48x0Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6m5UOXClc5v",
        "colab_type": "text"
      },
      "source": [
        "#Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT5sY3dasl51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_data = 'drive/My Drive/Colab Notebooks/RemoteML/Data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgRZ3Vnfv47E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_files = glob.glob(path_data + \"/*.json\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_json(filename)\n",
        "    li.append(df)\n",
        "\n",
        "df = pd.concat(li, axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rve-eLKOxTie",
        "colab_type": "code",
        "outputId": "bf3d7e87-d6e4-497e-9a9c-4d2fc5a27685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(df[\"sentiment\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'', nan, 'negative', 'neutral', 'positive', 'not sure'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvkz7PADxdXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df[~((df[\"sentiment\"]== \"\"))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYd_wjeK8wX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.dropna(subset=['sentiment'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irSQt9J_7t1g",
        "colab_type": "code",
        "outputId": "e802bd1e-b230-4fa0-bcb7-7026e965be37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(df1[\"sentiment\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neutral', 'positive', 'negative', 'not sure'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-1kbONN7tyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df1.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960xD5tVJklZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WoG5tCn7tvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = list(df1[\"content\"])\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(list(df1[\"sentiment\"]))\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, stratify=ytrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGDELtVVxoNH",
        "colab_type": "code",
        "outputId": "5bb322bc-d1ab-43cb-9ed3-3bfc35e80503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "Xtrain[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['De eerste nieuwe uitlopers zijn er vast aan gehangen  hij gaat als een trein. Met beide planten heel blij  allebei rare soorten. Ik ga nog wel aluin begraven bij de hortensia  hopelijk komt de blauwe kleur dan ook hier terug.',\n",
              " 'Het beste nieuws voor de mensheid sinds tijden by far. Genetische modificatie wordt toegestaan https://fd.nl/economie-politiek/1185108/blokkade-van-genetische-manipulatie-wankelt #GMO',\n",
              " 'Dat was nu juist datgene dat uit voorzorgsprincipe eerst maar eens grondig onderzocht moet worden voordat de mensheid hieraan wordt blootgesteld. Mijn conclusie gaat dan ook over de biodiversiteit: \\nDuidelijk is dat GMO de natuurlijke gewassen aan het verdingen is  Een conclusie die vele wetenschappers zullen kunnen onderschrijven. Boeren worden door ongewenste bestuiving van natuurlijke gewassen door GMO beschuldigd van patent schendingen.',\n",
              " 'En dat zal altijd zo zijn. | Title: Grootschalig onderzoek: GMO-voedsel veilig om te eten',\n",
              " 'RT @Maaike_Bionext A. O. Biotechnologie Esther ouwehand  pleit voor behoud  procesbenadering en voorzorgbeginsel in GMO regelgeving @BionextTweets']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jgOdApgxoJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    Xtrain, target_vocab_size=5000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjUmOvZ05WbH",
        "colab_type": "code",
        "outputId": "650b22f8-fc4a-47b4-8b21-58c23b1a9157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_string = 'Veel beter is het dikke lookbollen uit Arleux te kopen'\n",
        "\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized string is [3195, 416, 10, 7, 4607, 961, 3007, 354, 177, 42, 438, 1631, 1558, 11, 746]\n",
            "The original string: Veel beter is het dikke lookbollen uit Arleux te kopen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRcDXRNG5F8I",
        "colab_type": "code",
        "outputId": "6a199090-aa07-4f42-844c-f7139b6fdeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "Xtraintoke = [tokenizer.encode(s) for s in Xtrain]\n",
        "train = [(text,ytrain[i]) for (i,text) in enumerate(Xtraintoke)]\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM_G0-qgtR80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xvaltoke = [tokenizer.encode(s) for s in Xval]\n",
        "val = [(text,yval[i]) for (i,text) in enumerate(Xvaltoke)]\n",
        "val_dataset = tf.data.Dataset.from_generator(lambda: val, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7hvX0-tSIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtesttoke = [tokenizer.encode(s) for s in Xtest]\n",
        "test = [(text,ytest[i]) for (i,text) in enumerate(Xtesttoke)]\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhqwntU9DknC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 32\n",
        "MAX_LENGTH = 80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4GhL3SluuXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = MAX_LENGTH\n",
        "def pad_or_trunc(t,s):\n",
        "    \n",
        "    dim = tf.size(t)\n",
        "    return (tf.cond(tf.equal(dim, k), lambda: t, lambda: tf.cond(tf.greater(dim, k), lambda: tf.slice(t, [0], [k]), lambda: tf.concat([t, tf.zeros(k-dim, dtype=tf.int32)], 0))),s)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul7rM5Hiu-l9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_dataset = train_dataset.map(pad_or_trunc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoZbRTGUxn_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "#train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
        "train_dataset = train_dataset.repeat(40)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9cDbyuPuNZ6",
        "colab_type": "code",
        "outputId": "db4f24ec-1d7a-4b7a-b7ce-10566ea24bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "batch = next(iter(train_dataset))\n",
        "batch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=99, shape=(32, 93), dtype=int32, numpy=\n",
              " array([[ 361,  703,   95, ...,    0,    0,    0],\n",
              "        [  59,   31, 3756, ..., 3268, 5040, 4993],\n",
              "        [1695, 2983, 4972, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [1706, 3410, 3987, ...,    0,    0,    0],\n",
              "        [5022, 5025, 5025, ...,    0,    0,    0],\n",
              "        [4806, 1394, 3815, ...,    0,    0,    0]], dtype=int32)>,\n",
              " <tf.Tensor: id=100, shape=(32,), dtype=int32, numpy=\n",
              " array([1, 3, 1, 1, 1, 1, 1, 1, 0, 3, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 3,\n",
              "        1, 3, 3, 1, 1, 1, 1, 1, 3, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx1O1CqBt8oo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
        "test_dataset = test_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "## Positional encoding\n",
        "\n",
        "Since this model doesn't contain any recurrence or convolution, positional encoding is added to give the model some information about the relative position of the words in the sentence. \n",
        "\n",
        "The positional encoding vector is added to the embedding vector. Embeddings represent a token in a d-dimensional space where tokens with similar meaning will be closer to each other. But the embeddings do not encode the relative position of words in a sentence. So after adding the positional encoding, words will be closer to each other based on the *similarity of their meaning and their position in the sentence*, in the d-dimensional space.\n",
        "\n",
        "See the notebook on [positional encoding](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) to learn more about it. The formula for calculating the positional encoding is as follows:\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WhIOZjMNKujn",
        "colab": {}
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rz82wEs5biZ",
        "colab": {}
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value `0` is present: it outputs a `1` at those locations, and a `0` otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2i8-e1s8ti9",
        "colab": {}
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LazzUq3bJ5SH",
        "colab": {}
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "  \"\"\"\n",
        "\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
        "\n",
        "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n90YjClyInFy",
        "colab": {}
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads. \n",
        "\n",
        "The `scaled_dot_product_attention` defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step.  The attention output for each head is then concatenated (using `tf.transpose`, and `tf.reshape`) and put through a final `Dense` layer.\n",
        "\n",
        "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BSV3PPKsYecw",
        "colab": {}
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "Create a `MultiHeadAttention` layer to try out. At each location in the sequence, `y`, the `MultiHeadAttention` runs all 8 attention heads across all other locations in the sequence, returning a new vector of the same length at each location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hu94p-_-2_BX",
        "outputId": "aba17252-ed9b-4c89-8be4-c2169103389b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RdDqGayx67vv"
      },
      "source": [
        "## Point wise feed forward network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "Point wise feed forward network consists of two fully-connected layers with a ReLU activation in between."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ET7xLt0yCT6Z",
        "colab": {}
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mytb1lPyOHLB",
        "outputId": "80a42bae-e7ef-47b6-e758-f7365d87a750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "### Encoder layer\n",
        "\n",
        "Each encoder layer consists of sublayers:\n",
        "\n",
        "1.   Multi-head attention (with padding mask) \n",
        "2.    Point wise feed forward networks. \n",
        "\n",
        "Each of these sublayers has a residual connection around it followed by a layer normalization. Residual connections help in avoiding the vanishing gradient problem in deep networks.\n",
        "\n",
        "The output of each sublayer is `LayerNorm(x + Sublayer(x))`. The normalization is done on the `d_model` (last) axis. There are N encoder layers in the transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncyS-Ms3i2x_",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzZRXdO0mI48",
        "outputId": "1a4312d2-ef3d-4480-baea-5043a55416e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "The `Encoder` consists of:\n",
        "1.   Input Embedding\n",
        "2.   Positional Encoding\n",
        "3.   N encoder layers\n",
        "\n",
        "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jpEox7gJ8FCI",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8QG9nueFQKXx",
        "outputId": "fb34c967-090c-48da-9b0b-ca2d9cb40eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500)\n",
        "\n",
        "sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n",
        "                                       training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 62, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "## Create the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uERO1y54cOKq"
      },
      "source": [
        "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PED3bIpOYkBu",
        "colab": {}
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               classes_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    #self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "    #                       target_vocab_size, rate)\n",
        "    \n",
        "    self.rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(d_model))\n",
        "    \n",
        "   \n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(classes_size, activation='softmax')\n",
        "    \n",
        "  def call(self, inp, training, enc_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    #print(enc_output.shape)\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    output = self.rnn(enc_output)\n",
        "    #print(output.shape)\n",
        "    \n",
        "    final_output = self.final_layer(output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tJ4fbQcIkHW1",
        "outputId": "2aa02b8e-6f86-4fb9-9873-a1dfee10854e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=1, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=8500, classes_size=4)\n",
        "\n",
        "\n",
        "temp_input = tf.random.uniform((64, 62))\n",
        "fn_out = sample_transformer(temp_input, training=False, \n",
        "                               enc_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
        "\n",
        "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
        "\n",
        "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnJn5SLA2ahP",
        "colab": {}
      },
      "source": [
        "num_layers = 1\n",
        "d_model = 128\n",
        "dff = 256\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer.vocab_size + 2\n",
        "classes_size=4\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iYQdOO1axwEI",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7r4scdulztRx",
        "colab": {}
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "## Loss and metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MlhsJMm0TW_B",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67oqVHiT0Eiu",
        "colab": {}
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "phlyxMnm-Tpx",
        "colab": {}
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "## Training and checkpointing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiysUa--4tOU",
        "colab": {}
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, classes_size, dropout_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZOJUSB1T8GjM",
        "colab": {}
      },
      "source": [
        "def create_masks(inp):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  return enc_padding_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hNhuYfllndLZ",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "#if ckpt_manager.latest_checkpoint:\n",
        "#  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "The target is divided into tar_inp and tar_real. tar_inp is passed as an input to the decoder. `tar_real` is that same input shifted by 1: At each location in `tar_input`, `tar_real` contains the  next token that should be predicted.\n",
        "\n",
        "For example, `sentence` = \"SOS A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "The transformer is an auto-regressive model: it makes predictions one part at a time, and uses its output so far to decide what to do next. \n",
        "\n",
        "During training this example uses teacher-forcing (like in the [text generation tutorial](./text_generation.ipynb)). Teacher forcing is passing the true output to the next time step regardless of what the model predicts at the current time step.\n",
        "\n",
        "As the transformer predicts each word, *self-attention* allows it to look at the previous words in the input sequence to better predict the next word.\n",
        "\n",
        "To prevent the model from peaking at the expected output the model uses a look-ahead mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LKpoA6q1sJFj",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJwmp9OE29oj",
        "colab": {}
      },
      "source": [
        "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
        "# execution. The function specializes to the precise shape of the argument\n",
        "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
        "# batch sizes (the last batch is smaller), use input_signature to specify\n",
        "# more generic shapes.\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  loss = 0\n",
        "  enc_padding_mask= create_masks(inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = transformer(inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask)\n",
        "    loss = loss_function(tar, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  print(loss)\n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbvmaKNiznHZ",
        "outputId": "64a5d39f-4637-4839-80e3-397ea61e0687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 10 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
            "Epoch 1 Batch 0 Loss 1.2592 Accuracy 0.0938\n",
            "Epoch 1 Batch 10 Loss 1.3235 Accuracy 0.1705\n",
            "Epoch 1 Batch 20 Loss 1.3246 Accuracy 0.2024\n",
            "Epoch 1 Batch 30 Loss 1.3081 Accuracy 0.2722\n",
            "Epoch 1 Batch 40 Loss 1.2945 Accuracy 0.3590\n",
            "Epoch 1 Batch 50 Loss 1.2779 Accuracy 0.4252\n",
            "Epoch 1 Batch 60 Loss 1.2492 Accuracy 0.4688\n",
            "Epoch 1 Batch 70 Loss 1.2257 Accuracy 0.4915\n",
            "Epoch 1 Batch 80 Loss 1.1971 Accuracy 0.5199\n",
            "Epoch 1 Batch 90 Loss 1.1767 Accuracy 0.5339\n",
            "Epoch 1 Batch 100 Loss 1.1637 Accuracy 0.5449\n",
            "Epoch 1 Batch 110 Loss 1.1470 Accuracy 0.5556\n",
            "Epoch 1 Batch 120 Loss 1.1333 Accuracy 0.5668\n",
            "Epoch 1 Batch 130 Loss 1.1197 Accuracy 0.5761\n",
            "Epoch 1 Batch 140 Loss 1.1122 Accuracy 0.5813\n",
            "Epoch 1 Batch 150 Loss 1.1026 Accuracy 0.5888\n",
            "Epoch 1 Batch 160 Loss 1.0945 Accuracy 0.5946\n",
            "Epoch 1 Batch 170 Loss 1.0897 Accuracy 0.5973\n",
            "Epoch 1 Batch 180 Loss 1.0842 Accuracy 0.6034\n",
            "Epoch 1 Batch 190 Loss 1.0756 Accuracy 0.6069\n",
            "Epoch 1 Batch 200 Loss 1.0704 Accuracy 0.6086\n",
            "Epoch 1 Batch 210 Loss 1.0660 Accuracy 0.6105\n",
            "Epoch 1 Batch 220 Loss 1.0616 Accuracy 0.6129\n",
            "Epoch 1 Batch 230 Loss 1.0606 Accuracy 0.6145\n",
            "Epoch 1 Batch 240 Loss 1.0569 Accuracy 0.6182\n",
            "Epoch 1 Batch 250 Loss 1.0533 Accuracy 0.6205\n",
            "Epoch 1 Batch 260 Loss 1.0492 Accuracy 0.6244\n",
            "Epoch 1 Batch 270 Loss 1.0465 Accuracy 0.6255\n",
            "Epoch 1 Batch 280 Loss 1.0428 Accuracy 0.6281\n",
            "Epoch 1 Batch 290 Loss 1.0409 Accuracy 0.6293\n",
            "Epoch 1 Batch 300 Loss 1.0383 Accuracy 0.6315\n",
            "Epoch 1 Batch 310 Loss 1.0373 Accuracy 0.6326\n",
            "Epoch 1 Batch 320 Loss 1.0348 Accuracy 0.6331\n",
            "Epoch 1 Batch 330 Loss 1.0342 Accuracy 0.6335\n",
            "Epoch 1 Batch 340 Loss 1.0326 Accuracy 0.6348\n",
            "Epoch 1 Batch 350 Loss 1.0314 Accuracy 0.6355\n",
            "Epoch 1 Batch 360 Loss 1.0305 Accuracy 0.6358\n",
            "Epoch 1 Batch 370 Loss 1.0288 Accuracy 0.6374\n",
            "Epoch 1 Batch 380 Loss 1.0286 Accuracy 0.6374\n",
            "Epoch 1 Batch 390 Loss 1.0259 Accuracy 0.6394\n",
            "Epoch 1 Batch 400 Loss 1.0245 Accuracy 0.6405\n",
            "Epoch 1 Batch 410 Loss 1.0233 Accuracy 0.6408\n",
            "Epoch 1 Batch 420 Loss 1.0224 Accuracy 0.6421\n",
            "Epoch 1 Batch 430 Loss 1.0210 Accuracy 0.6433\n",
            "Epoch 1 Batch 440 Loss 1.0189 Accuracy 0.6438\n",
            "Epoch 1 Batch 450 Loss 1.0184 Accuracy 0.6447\n",
            "Epoch 1 Batch 460 Loss 1.0178 Accuracy 0.6449\n",
            "Epoch 1 Batch 470 Loss 1.0167 Accuracy 0.6452\n",
            "Epoch 1 Batch 480 Loss 1.0157 Accuracy 0.6463\n",
            "Epoch 1 Batch 490 Loss 1.0142 Accuracy 0.6473\n",
            "Epoch 1 Batch 500 Loss 1.0130 Accuracy 0.6481\n",
            "Epoch 1 Batch 510 Loss 1.0128 Accuracy 0.6484\n",
            "Epoch 1 Batch 520 Loss 1.0134 Accuracy 0.6472\n",
            "Epoch 1 Batch 530 Loss 1.0122 Accuracy 0.6481\n",
            "Epoch 1 Batch 540 Loss 1.0114 Accuracy 0.6483\n",
            "Epoch 1 Batch 550 Loss 1.0105 Accuracy 0.6487\n",
            "Epoch 1 Batch 560 Loss 1.0100 Accuracy 0.6486\n",
            "Epoch 1 Batch 570 Loss 1.0099 Accuracy 0.6484\n",
            "Epoch 1 Batch 580 Loss 1.0094 Accuracy 0.6491\n",
            "Epoch 1 Batch 590 Loss 1.0086 Accuracy 0.6500\n",
            "Epoch 1 Batch 600 Loss 1.0078 Accuracy 0.6508\n",
            "Epoch 1 Batch 610 Loss 1.0079 Accuracy 0.6508\n",
            "Epoch 1 Batch 620 Loss 1.0073 Accuracy 0.6508\n",
            "Epoch 1 Batch 630 Loss 1.0071 Accuracy 0.6511\n",
            "Epoch 1 Batch 640 Loss 1.0065 Accuracy 0.6518\n",
            "Epoch 1 Batch 650 Loss 1.0060 Accuracy 0.6524\n",
            "Epoch 1 Batch 660 Loss 1.0054 Accuracy 0.6529\n",
            "Epoch 1 Batch 670 Loss 1.0046 Accuracy 0.6531\n",
            "Epoch 1 Batch 680 Loss 1.0047 Accuracy 0.6534\n",
            "Epoch 1 Batch 690 Loss 1.0048 Accuracy 0.6534\n",
            "Epoch 1 Batch 700 Loss 1.0038 Accuracy 0.6541\n",
            "Epoch 1 Batch 710 Loss 1.0035 Accuracy 0.6546\n",
            "Epoch 1 Batch 720 Loss 1.0031 Accuracy 0.6543\n",
            "Epoch 1 Batch 730 Loss 1.0028 Accuracy 0.6543\n",
            "Epoch 1 Batch 740 Loss 1.0013 Accuracy 0.6551\n",
            "Epoch 1 Batch 750 Loss 1.0004 Accuracy 0.6559\n",
            "Epoch 1 Batch 760 Loss 1.0004 Accuracy 0.6566\n",
            "Epoch 1 Batch 770 Loss 1.0002 Accuracy 0.6562\n",
            "Epoch 1 Batch 780 Loss 0.9996 Accuracy 0.6563\n",
            "Epoch 1 Batch 790 Loss 1.0000 Accuracy 0.6563\n",
            "Epoch 1 Batch 800 Loss 1.0001 Accuracy 0.6562\n",
            "Epoch 1 Batch 810 Loss 0.9996 Accuracy 0.6564\n",
            "Epoch 1 Batch 820 Loss 0.9994 Accuracy 0.6566\n",
            "Epoch 1 Batch 830 Loss 0.9994 Accuracy 0.6566\n",
            "Epoch 1 Batch 840 Loss 0.9991 Accuracy 0.6567\n",
            "Epoch 1 Batch 850 Loss 0.9991 Accuracy 0.6567\n",
            "Epoch 1 Batch 860 Loss 0.9989 Accuracy 0.6571\n",
            "Epoch 1 Batch 870 Loss 0.9980 Accuracy 0.6575\n",
            "Epoch 1 Batch 880 Loss 0.9971 Accuracy 0.6582\n",
            "Epoch 1 Batch 890 Loss 0.9966 Accuracy 0.6585\n",
            "Epoch 1 Batch 900 Loss 0.9965 Accuracy 0.6585\n",
            "Epoch 1 Batch 910 Loss 0.9964 Accuracy 0.6587\n",
            "Epoch 1 Batch 920 Loss 0.9966 Accuracy 0.6585\n",
            "Epoch 1 Batch 930 Loss 0.9965 Accuracy 0.6584\n",
            "Epoch 1 Batch 940 Loss 0.9963 Accuracy 0.6586\n",
            "Epoch 1 Batch 950 Loss 0.9957 Accuracy 0.6590\n",
            "Epoch 1 Batch 960 Loss 0.9955 Accuracy 0.6592\n",
            "Epoch 1 Batch 970 Loss 0.9955 Accuracy 0.6592\n",
            "Epoch 1 Batch 980 Loss 0.9955 Accuracy 0.6592\n",
            "Epoch 1 Batch 990 Loss 0.9950 Accuracy 0.6597\n",
            "Epoch 1 Batch 1000 Loss 0.9951 Accuracy 0.6596\n",
            "Epoch 1 Batch 1010 Loss 0.9950 Accuracy 0.6597\n",
            "Epoch 1 Batch 1020 Loss 0.9951 Accuracy 0.6597\n",
            "Epoch 1 Batch 1030 Loss 0.9954 Accuracy 0.6596\n",
            "Epoch 1 Batch 1040 Loss 0.9951 Accuracy 0.6594\n",
            "Epoch 1 Batch 1050 Loss 0.9947 Accuracy 0.6597\n",
            "Epoch 1 Batch 1060 Loss 0.9945 Accuracy 0.6600\n",
            "Epoch 1 Batch 1070 Loss 0.9944 Accuracy 0.6602\n",
            "Epoch 1 Batch 1080 Loss 0.9943 Accuracy 0.6600\n",
            "Epoch 1 Batch 1090 Loss 0.9940 Accuracy 0.6601\n",
            "Epoch 1 Batch 1100 Loss 0.9938 Accuracy 0.6603\n",
            "Epoch 1 Batch 1110 Loss 0.9932 Accuracy 0.6608\n",
            "Epoch 1 Batch 1120 Loss 0.9932 Accuracy 0.6611\n",
            "Epoch 1 Batch 1130 Loss 0.9931 Accuracy 0.6611\n",
            "Epoch 1 Batch 1140 Loss 0.9934 Accuracy 0.6608\n",
            "Epoch 1 Batch 1150 Loss 0.9932 Accuracy 0.6607\n",
            "Epoch 1 Batch 1160 Loss 0.9929 Accuracy 0.6606\n",
            "Epoch 1 Batch 1170 Loss 0.9928 Accuracy 0.6610\n",
            "Epoch 1 Batch 1180 Loss 0.9923 Accuracy 0.6612\n",
            "Epoch 1 Batch 1190 Loss 0.9925 Accuracy 0.6612\n",
            "Epoch 1 Batch 1200 Loss 0.9922 Accuracy 0.6616\n",
            "Epoch 1 Batch 1210 Loss 0.9928 Accuracy 0.6616\n",
            "Epoch 1 Batch 1220 Loss 0.9930 Accuracy 0.6615\n",
            "Epoch 1 Batch 1230 Loss 0.9928 Accuracy 0.6616\n",
            "Epoch 1 Batch 1240 Loss 0.9927 Accuracy 0.6619\n",
            "Epoch 1 Batch 1250 Loss 0.9925 Accuracy 0.6617\n",
            "Epoch 1 Batch 1260 Loss 0.9922 Accuracy 0.6617\n",
            "Epoch 1 Batch 1270 Loss 0.9918 Accuracy 0.6621\n",
            "Epoch 1 Batch 1280 Loss 0.9915 Accuracy 0.6623\n",
            "Epoch 1 Batch 1290 Loss 0.9913 Accuracy 0.6626\n",
            "Epoch 1 Batch 1300 Loss 0.9915 Accuracy 0.6625\n",
            "Epoch 1 Batch 1310 Loss 0.9913 Accuracy 0.6626\n",
            "Epoch 1 Batch 1320 Loss 0.9914 Accuracy 0.6626\n",
            "Epoch 1 Batch 1330 Loss 0.9912 Accuracy 0.6628\n",
            "Epoch 1 Batch 1340 Loss 0.9909 Accuracy 0.6626\n",
            "Epoch 1 Batch 1350 Loss 0.9909 Accuracy 0.6627\n",
            "Epoch 1 Batch 1360 Loss 0.9907 Accuracy 0.6627\n",
            "Epoch 1 Batch 1370 Loss 0.9908 Accuracy 0.6626\n",
            "Epoch 1 Batch 1380 Loss 0.9904 Accuracy 0.6630\n",
            "Epoch 1 Batch 1390 Loss 0.9904 Accuracy 0.6627\n",
            "Epoch 1 Batch 1400 Loss 0.9906 Accuracy 0.6627\n",
            "Epoch 1 Batch 1410 Loss 0.9903 Accuracy 0.6629\n",
            "Epoch 1 Batch 1420 Loss 0.9903 Accuracy 0.6630\n",
            "Epoch 1 Batch 1430 Loss 0.9901 Accuracy 0.6631\n",
            "Epoch 1 Batch 1440 Loss 0.9900 Accuracy 0.6633\n",
            "Epoch 1 Batch 1450 Loss 0.9902 Accuracy 0.6633\n",
            "Epoch 1 Batch 1460 Loss 0.9902 Accuracy 0.6635\n",
            "Epoch 1 Batch 1470 Loss 0.9898 Accuracy 0.6635\n",
            "Epoch 1 Batch 1480 Loss 0.9898 Accuracy 0.6633\n",
            "Epoch 1 Batch 1490 Loss 0.9898 Accuracy 0.6634\n",
            "Epoch 1 Batch 1500 Loss 0.9899 Accuracy 0.6634\n",
            "Epoch 1 Batch 1510 Loss 0.9899 Accuracy 0.6634\n",
            "Epoch 1 Batch 1520 Loss 0.9897 Accuracy 0.6636\n",
            "Epoch 1 Batch 1530 Loss 0.9893 Accuracy 0.6640\n",
            "Epoch 1 Batch 1540 Loss 0.9893 Accuracy 0.6639\n",
            "Epoch 1 Batch 1550 Loss 0.9891 Accuracy 0.6642\n",
            "Epoch 1 Batch 1560 Loss 0.9890 Accuracy 0.6641\n",
            "Epoch 1 Batch 1570 Loss 0.9888 Accuracy 0.6643\n",
            "Epoch 1 Batch 1580 Loss 0.9889 Accuracy 0.6642\n",
            "Epoch 1 Batch 1590 Loss 0.9889 Accuracy 0.6643\n",
            "Epoch 1 Batch 1600 Loss 0.9890 Accuracy 0.6642\n",
            "Epoch 1 Batch 1610 Loss 0.9886 Accuracy 0.6644\n",
            "Epoch 1 Batch 1620 Loss 0.9887 Accuracy 0.6644\n",
            "Epoch 1 Batch 1630 Loss 0.9887 Accuracy 0.6644\n",
            "Epoch 1 Batch 1640 Loss 0.9887 Accuracy 0.6642\n",
            "Epoch 1 Batch 1650 Loss 0.9885 Accuracy 0.6644\n",
            "Epoch 1 Batch 1660 Loss 0.9884 Accuracy 0.6646\n",
            "Epoch 1 Batch 1670 Loss 0.9884 Accuracy 0.6646\n",
            "Epoch 1 Batch 1680 Loss 0.9884 Accuracy 0.6644\n",
            "Epoch 1 Batch 1690 Loss 0.9882 Accuracy 0.6645\n",
            "Epoch 1 Batch 1700 Loss 0.9882 Accuracy 0.6646\n",
            "Epoch 1 Batch 1710 Loss 0.9880 Accuracy 0.6647\n",
            "Epoch 1 Batch 1720 Loss 0.9880 Accuracy 0.6647\n",
            "Epoch 1 Batch 1730 Loss 0.9881 Accuracy 0.6647\n",
            "Epoch 1 Batch 1740 Loss 0.9880 Accuracy 0.6648\n",
            "Epoch 1 Batch 1750 Loss 0.9877 Accuracy 0.6648\n",
            "Epoch 1 Batch 1760 Loss 0.9876 Accuracy 0.6649\n",
            "Epoch 1 Batch 1770 Loss 0.9879 Accuracy 0.6647\n",
            "Epoch 1 Batch 1780 Loss 0.9878 Accuracy 0.6648\n",
            "Epoch 1 Batch 1790 Loss 0.9876 Accuracy 0.6650\n",
            "Epoch 1 Batch 1800 Loss 0.9876 Accuracy 0.6650\n",
            "Epoch 1 Batch 1810 Loss 0.9875 Accuracy 0.6652\n",
            "Epoch 1 Batch 1820 Loss 0.9876 Accuracy 0.6652\n",
            "Epoch 1 Batch 1830 Loss 0.9878 Accuracy 0.6652\n",
            "Epoch 1 Batch 1840 Loss 0.9875 Accuracy 0.6653\n",
            "Epoch 1 Batch 1850 Loss 0.9875 Accuracy 0.6651\n",
            "Epoch 1 Batch 1860 Loss 0.9873 Accuracy 0.6653\n",
            "Epoch 1 Batch 1870 Loss 0.9871 Accuracy 0.6654\n",
            "Epoch 1 Batch 1880 Loss 0.9870 Accuracy 0.6654\n",
            "Epoch 1 Batch 1890 Loss 0.9870 Accuracy 0.6655\n",
            "Epoch 1 Batch 1900 Loss 0.9871 Accuracy 0.6655\n",
            "Epoch 1 Batch 1910 Loss 0.9869 Accuracy 0.6656\n",
            "Epoch 1 Batch 1920 Loss 0.9870 Accuracy 0.6654\n",
            "Epoch 1 Batch 1930 Loss 0.9868 Accuracy 0.6653\n",
            "Epoch 1 Batch 1940 Loss 0.9867 Accuracy 0.6656\n",
            "Epoch 1 Batch 1950 Loss 0.9866 Accuracy 0.6656\n",
            "Epoch 1 Batch 1960 Loss 0.9866 Accuracy 0.6656\n",
            "Epoch 1 Batch 1970 Loss 0.9866 Accuracy 0.6658\n",
            "Epoch 1 Batch 1980 Loss 0.9866 Accuracy 0.6658\n",
            "Epoch 1 Batch 1990 Loss 0.9867 Accuracy 0.6657\n",
            "Epoch 1 Batch 2000 Loss 0.9866 Accuracy 0.6657\n",
            "Epoch 1 Batch 2010 Loss 0.9864 Accuracy 0.6659\n",
            "Epoch 1 Batch 2020 Loss 0.9862 Accuracy 0.6659\n",
            "Epoch 1 Batch 2030 Loss 0.9863 Accuracy 0.6659\n",
            "Epoch 1 Batch 2040 Loss 0.9863 Accuracy 0.6660\n",
            "Epoch 1 Batch 2050 Loss 0.9861 Accuracy 0.6662\n",
            "Epoch 1 Batch 2060 Loss 0.9861 Accuracy 0.6660\n",
            "Epoch 1 Batch 2070 Loss 0.9861 Accuracy 0.6661\n",
            "Epoch 1 Batch 2080 Loss 0.9863 Accuracy 0.6660\n",
            "Epoch 1 Batch 2090 Loss 0.9863 Accuracy 0.6662\n",
            "Epoch 1 Batch 2100 Loss 0.9863 Accuracy 0.6662\n",
            "Epoch 1 Batch 2110 Loss 0.9861 Accuracy 0.6664\n",
            "Epoch 1 Batch 2120 Loss 0.9861 Accuracy 0.6665\n",
            "Epoch 1 Batch 2130 Loss 0.9860 Accuracy 0.6665\n",
            "Epoch 1 Batch 2140 Loss 0.9860 Accuracy 0.6663\n",
            "Epoch 1 Batch 2150 Loss 0.9860 Accuracy 0.6663\n",
            "Epoch 1 Batch 2160 Loss 0.9860 Accuracy 0.6662\n",
            "Epoch 1 Batch 2170 Loss 0.9861 Accuracy 0.6661\n",
            "Epoch 1 Batch 2180 Loss 0.9861 Accuracy 0.6662\n",
            "Epoch 1 Batch 2190 Loss 0.9859 Accuracy 0.6663\n",
            "Epoch 1 Batch 2200 Loss 0.9858 Accuracy 0.6664\n",
            "Epoch 1 Batch 2210 Loss 0.9858 Accuracy 0.6664\n",
            "Epoch 1 Batch 2220 Loss 0.9859 Accuracy 0.6663\n",
            "Epoch 1 Batch 2230 Loss 0.9859 Accuracy 0.6663\n",
            "Epoch 1 Batch 2240 Loss 0.9861 Accuracy 0.6663\n",
            "Epoch 1 Batch 2250 Loss 0.9859 Accuracy 0.6664\n",
            "Epoch 1 Batch 2260 Loss 0.9857 Accuracy 0.6664\n",
            "Epoch 1 Batch 2270 Loss 0.9856 Accuracy 0.6665\n",
            "Epoch 1 Batch 2280 Loss 0.9857 Accuracy 0.6666\n",
            "Epoch 1 Batch 2290 Loss 0.9856 Accuracy 0.6665\n",
            "Epoch 1 Batch 2300 Loss 0.9856 Accuracy 0.6665\n",
            "Epoch 1 Batch 2310 Loss 0.9856 Accuracy 0.6665\n",
            "Epoch 1 Batch 2320 Loss 0.9854 Accuracy 0.6666\n",
            "Epoch 1 Batch 2330 Loss 0.9854 Accuracy 0.6667\n",
            "Epoch 1 Batch 2340 Loss 0.9854 Accuracy 0.6667\n",
            "Epoch 1 Batch 2350 Loss 0.9855 Accuracy 0.6667\n",
            "Epoch 1 Batch 2360 Loss 0.9853 Accuracy 0.6669\n",
            "Epoch 1 Batch 2370 Loss 0.9853 Accuracy 0.6667\n",
            "Epoch 1 Batch 2380 Loss 0.9854 Accuracy 0.6666\n",
            "Epoch 1 Batch 2390 Loss 0.9851 Accuracy 0.6669\n",
            "Epoch 1 Batch 2400 Loss 0.9851 Accuracy 0.6669\n",
            "Epoch 1 Batch 2410 Loss 0.9852 Accuracy 0.6669\n",
            "Epoch 1 Batch 2420 Loss 0.9853 Accuracy 0.6668\n",
            "Epoch 1 Batch 2430 Loss 0.9851 Accuracy 0.6669\n",
            "Epoch 1 Batch 2440 Loss 0.9852 Accuracy 0.6669\n",
            "Epoch 1 Batch 2450 Loss 0.9850 Accuracy 0.6670\n",
            "Epoch 1 Batch 2460 Loss 0.9849 Accuracy 0.6670\n",
            "Epoch 1 Batch 2470 Loss 0.9850 Accuracy 0.6669\n",
            "Epoch 1 Batch 2480 Loss 0.9849 Accuracy 0.6671\n",
            "Epoch 1 Batch 2490 Loss 0.9847 Accuracy 0.6672\n",
            "Epoch 1 Batch 2500 Loss 0.9847 Accuracy 0.6672\n",
            "Epoch 1 Batch 2510 Loss 0.9848 Accuracy 0.6671\n",
            "Epoch 1 Batch 2520 Loss 0.9848 Accuracy 0.6671\n",
            "Epoch 1 Batch 2530 Loss 0.9847 Accuracy 0.6670\n",
            "Epoch 1 Batch 2540 Loss 0.9847 Accuracy 0.6672\n",
            "Epoch 1 Batch 2550 Loss 0.9847 Accuracy 0.6673\n",
            "Epoch 1 Batch 2560 Loss 0.9846 Accuracy 0.6674\n",
            "Epoch 1 Batch 2570 Loss 0.9846 Accuracy 0.6674\n",
            "Epoch 1 Batch 2580 Loss 0.9845 Accuracy 0.6674\n",
            "Epoch 1 Batch 2590 Loss 0.9843 Accuracy 0.6675\n",
            "Epoch 1 Batch 2600 Loss 0.9845 Accuracy 0.6674\n",
            "Epoch 1 Batch 2610 Loss 0.9845 Accuracy 0.6674\n",
            "Epoch 1 Batch 2620 Loss 0.9845 Accuracy 0.6674\n",
            "Epoch 1 Batch 2630 Loss 0.9843 Accuracy 0.6674\n",
            "Epoch 1 Batch 2640 Loss 0.9844 Accuracy 0.6673\n",
            "Epoch 1 Batch 2650 Loss 0.9845 Accuracy 0.6672\n",
            "Epoch 1 Batch 2660 Loss 0.9843 Accuracy 0.6674\n",
            "Epoch 1 Batch 2670 Loss 0.9842 Accuracy 0.6675\n",
            "Epoch 1 Loss 0.9843 Accuracy 0.6676\n",
            "Time taken for 1 epoch: 311.8404862880707 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}