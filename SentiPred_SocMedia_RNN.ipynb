{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentiPred_SocMedia_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juglar-diaz/SentimentAnalysis/blob/master/SentiPred_SocMedia_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02j_-p6TZ2r",
        "colab_type": "text"
      },
      "source": [
        "#Intro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3QjBnH6lktK",
        "colab_type": "code",
        "outputId": "b1b0c83a-3c93-4ddd-c762-77f129feaaf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leX0hKWxlPaF",
        "colab_type": "code",
        "outputId": "9013b7c4-527e-4c9f-934f-af8d76a8e65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install stop_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp36-none-any.whl size=32916 sha256=365ec90e98633dec51eadb43f8f548bf51823b99f95937e305b025d165c454d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsKFofSByI9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -q tensorflow-text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PosahS5t0nH3",
        "colab_type": "code",
        "outputId": "4a833a9c-f7d5-468c-c689-0fb6a952cd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "#!pip install -q tf-nightly-gpu-2.0-preview\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 348.9MB 50kB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 44.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 40.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhfa7bn4ypPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeqX7HRpBigk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "from collections import Counter\n",
        "from stop_words import get_stop_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b9kkYk9lXhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4n58fkig5KL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import itertools\n",
        "\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "sep = os.sep\n",
        "import os.path\n",
        "\n",
        "import pandas as pd\n",
        "import bisect\n",
        "import time\n",
        "import scipy.stats as stats\n",
        "\n",
        "import datetime\n",
        "\n",
        "import glob\n",
        "from sklearn import metrics\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jjmwC48x0Lh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6m5UOXClc5v",
        "colab_type": "text"
      },
      "source": [
        "#Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT5sY3dasl51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_data = 'drive/My Drive/Colab Notebooks/RemoteML/Data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnskzj5wx-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_json(path_data+\"dutch1.json\")\n",
        "#train.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgRZ3Vnfv47E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_files = glob.glob(path_data + \"/*.json\")\n",
        "\n",
        "li = []\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_json(filename)\n",
        "    li.append(df)\n",
        "\n",
        "df = pd.concat(li, axis=0, ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rve-eLKOxTie",
        "colab_type": "code",
        "outputId": "1ed799d3-a48d-4d90-87c8-687f5d87de30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(df[\"sentiment\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'', 'negative', nan, 'neutral', 'not sure', 'positive'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvkz7PADxdXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df[~((df[\"sentiment\"]== \"\"))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYd_wjeK8wX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.dropna(subset=['sentiment'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irSQt9J_7t1g",
        "colab_type": "code",
        "outputId": "80532f15-2b25-461f-cac7-d91713b206c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(set(df1[\"sentiment\"]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'negative', 'not sure', 'positive', 'neutral'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-1kbONN7tyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df1.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "960xD5tVJklZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WoG5tCn7tvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = list(df1[\"content\"])\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(list(df1[\"sentiment\"]))\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, stratify=ytrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGDELtVVxoNH",
        "colab_type": "code",
        "outputId": "6d92ac6e-3654-4653-bade-01423a21c8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "Xtrain[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Oostvogel: 'Dit is een materiaal dat als goede vervanger kan dienen voor aluminium en carbon, maar voor 90 procent uit biologische grondstoffen is vervaardigd. Het voornaamste bestandsdeel van het bio-composiet is vlas, een plant met stugge vezels. Met Lina willen we laten zien dat auto’s ook op duurzame wijze lichter gemaakt kunnen worden.\",\n",
              " 'De ene aardappel is de andere niet maar allemaal zijn ze familie van de aubergine en tomaat. Daarom ook gevoelig voor dezelfde ziekten',\n",
              " 'Maar nu zag de boerin gisteren een gaaf filmpje op feestboek. Daar gebruikt een man molshopen om in te zaaien.Dus als je de tuin of je gazon wat meer (wilde) bloemen wilt geven.....Zaai dan in een molshoop. Ook leuk om buiten je eigen tuin te doen.Hoe meer bloemen voor de bijtjes, hommels en vlinders hoe beter! De boerin strooide in deze molshoop in de boomgaard Akelei-zaden.',\n",
              " 'Hi Semmy welke video heb je bekeken hoe groot de watermeloenen plant is?\\ufeff | Title: RE: Ah moestuintje seizoen 2 groei update, watermeloen, komkommer  en andijvie vraag 30',\n",
              " 'Het boek begint bij de lente, waar foto’s van ontspruitend groen afwisselen met niet al te ingewikkelde receptuur. Geschikt voor alle gelegenheden en tips voor het zaaien en verwerken van producten. Een boek over lekkere en bijzondere smaken voor iedere dag.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jgOdApgxoJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    Xtrain, target_vocab_size=5000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjUmOvZ05WbH",
        "colab_type": "code",
        "outputId": "bc9b853e-8a04-4cd8-ddb9-8685ea6af42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sample_string = 'Veel beter is het dikke lookbollen uit Arleux te kopen'\n",
        "\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized string is [2086, 945, 10, 7, 4490, 4833, 671, 3042, 388, 231, 42, 738, 1599, 1888, 12, 673]\n",
            "The original string: Veel beter is het dikke lookbollen uit Arleux te kopen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRcDXRNG5F8I",
        "colab_type": "code",
        "outputId": "fc613229-b635-4b49-fe3a-03ed818ddb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "Xtraintoke = [tokenizer.encode(s) for s in Xtrain]\n",
        "train = [(text,ytrain[i]) for (i,text) in enumerate(Xtraintoke)]\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM_G0-qgtR80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xvaltoke = [tokenizer.encode(s) for s in Xval]\n",
        "val = [(text,yval[i]) for (i,text) in enumerate(Xvaltoke)]\n",
        "val_dataset = tf.data.Dataset.from_generator(lambda: val, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7hvX0-tSIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtesttoke = [tokenizer.encode(s) for s in Xtest]\n",
        "test = [(text,ytest[i]) for (i,text) in enumerate(Xtesttoke)]\n",
        "test_dataset = tf.data.Dataset.from_generator(lambda: test, (tf.int32, tf.int32), (tf.TensorShape([None]), tf.TensorShape([])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fay4BqRJbdfs",
        "colab_type": "code",
        "outputId": "f97ce7d3-737d-4f81-a67a-5ae48a46d8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "iterator = iter(train_dataset)\n",
        "#print(next(iterator)[0].numpy())\n",
        "print(next(iterator))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: id=81, shape=(89,), dtype=int32, numpy=\n",
            "array([1279, 3334,  898,  171,   10,    8, 2994,   28,   43,  560, 1712,\n",
            "       4237, 4833,   62, 2048,    2,   13,  243,  411, 1461, 1305,    2,\n",
            "       4529, 2342,    5,   47,   13,  575, 4833,  522,   42,  491, 2637,\n",
            "       1727, 3098,   10, 1712, 2077, 4358,    3,   39,  107, 4246,  317,\n",
            "       4556, 1569, 2675,    4,    7,  569, 4846, 1830,  664, 1247, 4833,\n",
            "         10, 4001, 4916,    5,    8,   48,   20, 1125, 2643, 4833, 3339,\n",
            "       4916,    3,  236,  538,  205,  848,   63,  215,  326,   28, 1097,\n",
            "        181,   22,   37,   15, 3686, 3965, 3010,   77,  626,   72,  185,\n",
            "       4847], dtype=int32)>, <tf.Tensor: id=82, shape=(), dtype=int32, numpy=1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhqwntU9DknC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 5000\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoZbRTGUxn_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cache the dataset to memory to get a speedup while reading from it.\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n",
        "test_dataset = test_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None],[]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XorQwb3Hqz39",
        "colab_type": "code",
        "outputId": "1af93c5a-4dfe-4136-ffea-f0b52db51259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "iterator = iter(train_dataset)\n",
        "#print(next(iterator)[0].numpy())\n",
        "print(next(iterator))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: id=140, shape=(32, 123), dtype=int32, numpy=\n",
            "array([[  55,   31,  461, ...,    0,    0,    0],\n",
            "       [3853,  317, 2168, ...,    0,    0,    0],\n",
            "       [1669,   89,  408, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [1375, 4833, 1177, ...,    0,    0,    0],\n",
            "       [  55,   31, 1171, ...,    0,    0,    0],\n",
            "       [ 838,   88,  708, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: id=141, shape=(32,), dtype=int32, numpy=\n",
            "array([1, 2, 3, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1,\n",
            "       2, 1, 1, 0, 1, 1, 3, 1, 3, 0], dtype=int32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bgs6nnSTGw-t"
      },
      "source": [
        "Build a `tf.keras.Sequential` model and start with an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
        "\n",
        "This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a `tf.keras.layers.Dense` layer.\n",
        "\n",
        "A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input—and then to the next.\n",
        "\n",
        "The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the output. This helps the RNN to learn long range dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwfoBkmRYcP3",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sRI776ZcH3Tf"
      },
      "source": [
        "Compile the Keras model to configure the training process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kj2xei41YZjC",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zIwH3nto596k"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hw86wWS4YgR2",
        "outputId": "5c0e0729-fcf8-493f-ec43-c549e5c60cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_dataset, epochs=30,\n",
        "                    validation_data=test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "67/67 [==============================] - 34s 502ms/step - loss: 0.9896 - accuracy: 0.6642 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.8376 - accuracy: 0.6755 - val_loss: 0.9296 - val_accuracy: 0.6772\n",
            "Epoch 3/30\n",
            "67/67 [==============================] - 6s 83ms/step - loss: 0.5799 - accuracy: 0.7731 - val_loss: 1.1506 - val_accuracy: 0.5611\n",
            "Epoch 4/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.3686 - accuracy: 0.8599 - val_loss: 1.4005 - val_accuracy: 0.6033\n",
            "Epoch 5/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.1988 - accuracy: 0.9340 - val_loss: 1.5665 - val_accuracy: 0.5430\n",
            "Epoch 6/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.1563 - accuracy: 0.9458 - val_loss: 1.6044 - val_accuracy: 0.5701\n",
            "Epoch 7/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.1337 - accuracy: 0.9538 - val_loss: 1.6030 - val_accuracy: 0.6124\n",
            "Epoch 8/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.1432 - accuracy: 0.9500 - val_loss: 1.5279 - val_accuracy: 0.6048\n",
            "Epoch 9/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.1190 - accuracy: 0.9538 - val_loss: 1.6999 - val_accuracy: 0.5762\n",
            "Epoch 10/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.1104 - accuracy: 0.9547 - val_loss: 1.9905 - val_accuracy: 0.5626\n",
            "Epoch 11/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0992 - accuracy: 0.9571 - val_loss: 1.8173 - val_accuracy: 0.5686\n",
            "Epoch 12/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0927 - accuracy: 0.9575 - val_loss: 1.8376 - val_accuracy: 0.5852\n",
            "Epoch 13/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0843 - accuracy: 0.9608 - val_loss: 2.1353 - val_accuracy: 0.6109\n",
            "Epoch 14/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.0848 - accuracy: 0.9580 - val_loss: 2.4647 - val_accuracy: 0.6320\n",
            "Epoch 15/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0745 - accuracy: 0.9637 - val_loss: 2.4467 - val_accuracy: 0.6244\n",
            "Epoch 16/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.0683 - accuracy: 0.9599 - val_loss: 2.1992 - val_accuracy: 0.6078\n",
            "Epoch 17/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0601 - accuracy: 0.9627 - val_loss: 2.3385 - val_accuracy: 0.5973\n",
            "Epoch 18/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0586 - accuracy: 0.9590 - val_loss: 2.2783 - val_accuracy: 0.5988\n",
            "Epoch 19/30\n",
            "67/67 [==============================] - 6s 83ms/step - loss: 0.0544 - accuracy: 0.9590 - val_loss: 2.3678 - val_accuracy: 0.6003\n",
            "Epoch 20/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.0508 - accuracy: 0.9608 - val_loss: 2.5693 - val_accuracy: 0.5988\n",
            "Epoch 21/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.0493 - accuracy: 0.9613 - val_loss: 2.6120 - val_accuracy: 0.5988\n",
            "Epoch 22/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0478 - accuracy: 0.9608 - val_loss: 2.7321 - val_accuracy: 0.5913\n",
            "Epoch 23/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0468 - accuracy: 0.9623 - val_loss: 2.6946 - val_accuracy: 0.5928\n",
            "Epoch 24/30\n",
            "67/67 [==============================] - 6s 83ms/step - loss: 0.0464 - accuracy: 0.9594 - val_loss: 2.8230 - val_accuracy: 0.5897\n",
            "Epoch 25/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0461 - accuracy: 0.9618 - val_loss: 2.5461 - val_accuracy: 0.5958\n",
            "Epoch 26/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0457 - accuracy: 0.9627 - val_loss: 2.8170 - val_accuracy: 0.5897\n",
            "Epoch 27/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0446 - accuracy: 0.9646 - val_loss: 2.9387 - val_accuracy: 0.5882\n",
            "Epoch 28/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0437 - accuracy: 0.9642 - val_loss: 3.0179 - val_accuracy: 0.5913\n",
            "Epoch 29/30\n",
            "67/67 [==============================] - 6s 85ms/step - loss: 0.0436 - accuracy: 0.9637 - val_loss: 3.0051 - val_accuracy: 0.5913\n",
            "Epoch 30/30\n",
            "67/67 [==============================] - 6s 84ms/step - loss: 0.0433 - accuracy: 0.9646 - val_loss: 2.7588 - val_accuracy: 0.5867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7g1evcaRpTKm"
      },
      "source": [
        "## Stack two or more LSTM layers\n",
        "\n",
        "Keras recurrent layers have two available modes that are controlled by the `return_sequences` constructor argument:\n",
        "\n",
        "* Return either the full sequences of successive outputs for each timestep (a 3D tensor of shape `(batch_size, timesteps, output_features)`).\n",
        "* Return only the last output for each input sequence (a 2D tensor of shape (batch_size, output_features))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jo1jjO3vn0jo",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
        "        64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hEPV5jVGp-is",
        "colab": {}
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeSE-YjdqAeN",
        "outputId": "44ad1c8a-c62e-4440-c06a-f1b7ec857610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - 58s 865ms/step - loss: 0.9621 - accuracy: 0.6646 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.8571 - accuracy: 0.6726 - val_loss: 0.9803 - val_accuracy: 0.6697\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.5954 - accuracy: 0.7608 - val_loss: 1.2050 - val_accuracy: 0.5943\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 10s 152ms/step - loss: 0.3616 - accuracy: 0.8708 - val_loss: 1.4978 - val_accuracy: 0.4992\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 10s 149ms/step - loss: 0.2514 - accuracy: 0.9099 - val_loss: 1.6465 - val_accuracy: 0.6486\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.2254 - accuracy: 0.9255 - val_loss: 1.3172 - val_accuracy: 0.6154\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.1854 - accuracy: 0.9335 - val_loss: 1.5047 - val_accuracy: 0.5837\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.1530 - accuracy: 0.9439 - val_loss: 1.5583 - val_accuracy: 0.5596\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.1372 - accuracy: 0.9509 - val_loss: 1.8442 - val_accuracy: 0.5128\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 0.1217 - accuracy: 0.9528 - val_loss: 1.9607 - val_accuracy: 0.6199\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}